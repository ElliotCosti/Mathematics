\documentclass[12pt]{article}
\usepackage{amssymb}
\hoffset -25truemm
\usepackage{latexsym}
\oddsidemargin=27truemm             %%
\evensidemargin=25truemm            %% inner margin 30mm, outer margin 25mm
\textwidth=157truemm                %%
\voffset -25truemm
\topmargin=22truemm                 %% top margin of 25mm
\headheight=0truemm                 %% no head
\headsep=0truemm                    %% no head
\textheight=240truemm               
\renewcommand{\thefootnote}{}
\newtheorem{definition}{Definition}[section]
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{theorem}[definition]{Theorem}
\newtheorem{corollary}[definition]{Corollary}
\newtheorem{remark}[definition]{Remark}
\newtheorem{problem}[definition]{Problem}
\newenvironment{proof}{\normalsize {\sc Proof}:}{{\hfill $\Box$ \\}}

\def\SL{{\rm SL}}
\def\GL{{\rm GL}}
\def\U{{\rm U}}
\def\PSL{{\rm PSL}}
\def\PSp{{\rm PSp}}
\def\Stab{{\rm Stab}}
\def\PSU{{\rm PSU}}
\def\GF{{\rm GF}}
\def\Sp{{\rm Sp}}
\def\SU{{\rm SU}}
\def\SX{{\rm SX}}
\def\PX{{\rm PX}}
\def\GX{{\rm GX}}
\def\PSX{{\rm PSX}}
\def\PGL{{\rm PGL}}
\def\q{\quad}
\def\centreline{\centerline}

\begin{document}

\title{Reflection Groups and Coxeter Groups seminars}
\author{Elliot Costi}
\date{October 2007}
\maketitle

\newpage

\section{Positive and Simple Systems (1.3)}
\label{}

Recap: Given a vector space $V$, a root system $\Phi$ is a finite set of non-zero vectors of $V$ such that:

\begin{enumeratation}
\item{$\Phi \cap \mathbb{\alpha} = \{\alpha, -\alpha\}$ for all $\alpha \in \Phi$}
\item{$s_\alpha \Phi = \Phi$ for all $\alpha \in \Phi$}
\end{enumeration}
\\
$s_\alpha$ is the reflection in the hyperplane orthogonal to $\alpha$.
\\

Fix a root system $\Phi$ in $V = \mathbb{R}^n$ with $W$ the finite reflection group generated by all $s_\alpha, \alpha \in \Phi$.

There is a possiblity that $\Phi$ may be extremely large compared to the dimension of $V$. For example, if $W$ is a dihedral group, then $\Phi$ may have as many elements as $W$ even though dim $V = 2$.

So we wish to look for a linearly independent subset of $\Phi$, called a simple system such that $\Phi$ can be reconstituted. We want each root to be a linear combination over \mathbb{R} of simple roots with coefficients all of the same sign. We will be able to partition $\Phi$ into positive and negative roots all of like sign with one of each pair $\{\alpha, -\alpha\}$ being labelled as positive and the other as negative. We find such a partition by first totally ordering $V$.

Recap: A total ordering of a real vector space $V$ is a relation on $V$ denoted $<$ such that:

\begin{enumeratation}
\item{1. For all $\lambda, \mu \in V$ exactly one of $\lambda < \mu, \lambda = \mu$ or $\mu < \lambda$ hold.}
\item{2. For all $\lambda, \mu, v \in V$, if $\mu < v$, then $\lambda + \mu < \lamnda +v$.}
\item{3. If $\mu < v$ and $c \in \mathbb{R}$, then $c\mu < cv$ if $c > 0$ and $cv < c\mu$ if $c < 0$.}
\end{enumeratation}
\\

Having defined an ordering on $V$, we say that $v \in V$ is positive if $v > 0$. We define a total ordering on $V$ by choosing a basis $\{v_1, \dots, v_n\}$ and saying that $\Sigma a_i v_i < \Sigma b_i v_i$ if $a_k < b_k$ for some $k$ and $a_j = b_j$ for all $j < k$. For example, with respect to the standard basis for $\mathbb{R}^5$, (1 2 3 4 5) $<$ (1 2 3 9 5).

Given a total ordering on $V$, we call a subset $\Pi$ a positive system if consists of all the roots that are positive with respect to said total ordering. As all roots come in pairs, we can define the respective negative system $-\Pi$ in an obvious way and it is clear that $\Phi$ is the disjoint union of $\Pi$ and $-\Pi$.

A simple system $\Delta$ is subset of $\Phi$ if $\Delta$ forms a basis for the span of $\Phi$ in $V$ over $\mathbb{R}$ and also each $\alpha \in \Phi$ is a linear combination of $\Delta$ with all coefficients either nonnegative or nonpositive.

\begin{theorem}

a) If $\Delta$ is a simple system in $\Phi$ then there is a unique positive system contianing \Delta.

b) Every positive system $\Pi$ in $\Phi$ contains a unique simple system.
\end{theorem}

\begin{proof}
a) To see that a positive system exists, extend the linearly independent set $\Delta$ to an ordered basis of $V$ and take $\Pi$ to be the set of positive elements of $\Phi$ with respect to the lexicographical ordering. Clearly $\Delta$ is in $\Pi$.

Suppose that the simple system $\Delta$ is contained in a positive system $\Pi$. Then all roots that are nonnegative linear combinations of $\Delta$ must also be in $\Pi$ and their negatives, therefore, cannot be. So $\Pi$ is characterised uniquely as the set of all such roots.
\\

b) Let us first assume, that $\Pi$ DOES contain a simple system $\Delta$. Then $\Delta$ may be characterised as the set of all roots $\alpha \in \Pi$ such that $\alpha$ is not expressible as a linear combination of two or more elements of $\Pi$ with strictly positive coefficients. This would make $\Delta$ unique.

So how do we find such a system in $\Pi$? Choose a subset $\Delta$ of $\Pi$ such that each root of $\Pi$ is a nonnegative linear combination of elements of $\Delta$. We now prove that $\Delta$ is linearly independent. This will follow from the following condition that we need to prove: ($\alpha, \beta$) $\le 0$ for all pairs $\alpha \ne \beta$ in $\Delta$.

Suppose that this condition fails for some pair ($\alpha, \beta$). By the formula for the reflection, we have $s_\alpha \beta = \beta c \alpha$, with $c = 2(\beta, \alpha)/(\alpha, \alpha) > 0$. This shows that $s_\alpha \beta \in \Phi$ and so it is either negative or in $\Pi$. Let $s_\alpha \beta = \Sigma c_\gamma \gamma$, summing over $\gamma \in \Delta, c_\gamma \ge 0$. If $c_\beta < 1$, we get $s_\alpha \beta = \beta - c \alpha = c_\beta \beta + \Sigma_{\gamma \ne \beta} c_\gamma \gamma$. Rearranging we see that $(1 - c_\beta)\beta =$ nonnegative linear combinations of $\Delta - \{\beta\}$. As $a - c_\beta > 0$, we can remove $\beta$, which contradicts the minimality of $\Delta$. Now assume that $c_\beta \ge 1$. We now get that $0 = (c_\beta - 1)\beta + c \alpha + \Sigma_{\gamma \ne \beta} c_\gamma \gamma$. But a nonnegative linear combination of $\Delta$ with at least one positive coefficient can't equal 0 by definition of positive ordering. So $s_\alpha \beta$ cannot be positive. A similar argument shows that $s_\alpha \beta$ can't be negative. So the contradiction implies that the condition is true.

We now prove that $\Delta$ is linearly independent. Suppose not. Then $\Sigma_{\alpha \in \Delta} a_\alpha \alpha = 0$, with not all $a_\alpha = 0$. So arranging this equation so that we only have positive coefficients on both sides, we get this: $\Sigma b_\beta \beta = \Sigma c_\gamma \gamma$, where the sums are taken over disjoint subsets of $\Delta$. Call this sum $\sigma$. We have that $\sigma > 0$. By the condition that we proved: $0 \le (\sigma, \sigma) = (\Sigma b_\beta \beta , \Sigma c_\gamma \gamma) \le 0$. Hence, $\sigma = 0$, which is a contridiction.

So $\Delta$ is linearly independent and hence the result.
\end{proof}

The cardinality of any simple system is an invariant of $\Phi$, since it measures the dimension of the span of $\Phi$ in $V$. This cardinality is called the rank of $W$. For example, the Dihedral group has rank 2 and $S_n$ has rank $n - 1$.

\end{document}

